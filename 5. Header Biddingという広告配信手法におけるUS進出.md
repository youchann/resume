※社内の評価会にて作成した資料を外部向けに修正したものとなります

## 用語集

| 用語                            | 説明                                      |
|-------------------------------|-----------------------------------------|
| 社外向け管理画面   | 顧客向けに提供する管理画面 広告枠の設定やレポートの確認ができる。|
| Header Bidding (HB)           | ヘッダーに埋め込まれたスクリプトから同時に複数のSSPへリクエストを送り、最も高い金額で入札した広告が表示される。入札があるまで順番にリクエストを送るウォーターフォール方式に比べて公平性があり、媒体社にとっても収益増加が見込める。必要に応じて[この辺の記事](https://techlife.cookpad.com/entry/2018/06/18/101324)をベースに話す予定。                                       |
| Open Bidding(OB) 旧名称Exchange Bidding(EB)              | Googleの提供する広告配信方式。HBはクライアントからSSPにリクエストを送るのに対してOBは広告の表示枠が読み込まれるとGoogleのサーバー上でオークションが行われる違いがある。        |
| [Puppet](https://www.puppet.com/docs/puppet/8/puppet_index.html)                        |  マニフェストと呼ばれるファイルにサービスやコンフィグの情報を記述し、複数のサーバーで一貫した構成を維持する。                              |
| [Packer](https://www.packer.io/) | 起動イメージ（AWSはマシンイメージ）の構成をコードで管理し作成までを行うツール。今回はpuppetと併せて起動イメージの作成に使用|
| Impサーバー | 今回の作ったものとは別のすでにある仕組み。広告が表示された際にそのブラウザからImpサーバーにリクエストを送り、到達できた場合にインプレッションとしてカウントされる。広告はインプレッション量で課金額が決まるので、Impサーバーにきちんとリクエストが到達することは重要。 |
| [Redash](https://redash.io/) | 複数のDBに対してクエリを叩けるツール。弊社だとクラウド上にホストされててBiz/Eng両者が利用している状態。 |
| [Elastigroup](https://spot.io/product/elastigroup/)                   | spot by netappが提供するサービスの1つ。新しいマシンの起動時に複数のインスタンスタイプから1番安い物を選択し起動するので、コストを抑えられる。オートスケーリンググループの機能も持つ。                                       |

## 概要

- Header Biddingという手法での広告配信を海外の媒体社でも利用できるようにすべく諸々の開発を行なっていた
  - 前期（2023年1月〜5月）では、媒体社向けの管理画面を海外の方でも利用できるように開発
  - 後期（今回の話のスコープ）では、日本にしかなかった配信サーバーをUSにも配置
- これによりUSのインプレッションを主とする海外の媒体社とHeader Biddingによる取り組みを行うことができるようになった
- 現在は海外の媒体社に対して営業をかけている状態

## 期間

2023年〜半年以内

## 背景

### なぜ自分が行うのか

#### 手の空いている人がいなかった

- 配信系の業務を主とするメンバーが手がけた方が実現は早い（筆者は管理画面系を主とするメンバー）
- しかし当時、手の空いている人がいなかった

#### 所属するチームにおいて海外展開を目標に置いていた

- 先述の通り海外展開を狙って社外向けの管理画面を開発していた
- しかし広告配信システムの方も対応しなければ「海外展開した」とは言えない
- 目標が「海外展開」であればそれに関わる仕組みが全て「手がけるべきスコープ」と判断

### いつまでにやる必要があるのか

- 8月中には仕組みがあると良い、という話があった（5月25日時点）
  - あくまで目安（なる早問題ではある）
  - 進捗は要所で報告するスタイルだった
    - 認識を揃えるべきタイミングがあるので連携を取ることのほうが大事
      - 営業開拓を始めるタイミング
      - 媒体側の設定が完了して配信を始めるタイミング

## チーム

- 本件で関わった方々
  - Eng
    - 管理画面チーム
      - 筆者（メインで遂行）
    - SREチーム
      - Aさん（メインで遂行）
      - Bさん（メンター的な立ち位置）
- 所属しているチームを飛び出して、タスクフォース的に集まった

## ざっくり時系列

| 日付       |  進捗                              |
|------------|------------------------------------------|
| 2023/05/29 | キックオフMTG                             |
| 2023/06/01 | 情報収集・タスク整理開始（身内の不幸があり9営ほど休み）|
| 2023/07/03 | 手を動かし始める                             |
| 2023/07/20 | VMインスタンス起動できるところまで         |
| 2023/07/26 | Load Balancerに対してリクエストできることを確認まで |
| 2023/08/21 | 北米からのリクエストを実際に受けるところまで |
| 2023/09/01 | 9月中は別件の対応、Bizサイドが営業はじめる  |
| 2023/10/04 | 事業進捗の可視化                           |
| 2023/10/19 | 海外のお客さんと取引を始め出す |


## 評価してほしいポイント

- いわゆるフルサイクルな開発で売上を出す動きができていること
  - **既存のチームの枠を超えて活動してること**
- 配信の仕組みやGCPが全くわからない状態から情報収集をしてアウトプットに繋げたこと
- 成果（売上）を可観測にしたこと

## 作ったものの構成

概略的な構成図を下記に示す。なおこの画像は後述する「情報収集」のところでインプットを兼ねて書いた図となる。

（社内資料なので割愛）

## やったこと

チームではなく筆者個人がやったことをピックアップしていく。

### 情報整理

#### キックオフMTG

- 本当に何もわからないので、（配信いじっている人にとっては）基礎的なことを聞いていた

#### タスクの洗い出し

- 総じて、対応すべきはUSにサーバーをおくことだけということがわかった
- 「どうおくか？」をDesign Docで書いてみようか、という話に
  - 目線合わせとしては非常に役に立った
  - ※構成を書いたのはAさんであり、この時点で筆者はGCPのことが何もわかっていない

#### 情報収集

本件を進めるにあたって必要な情報が筆者の中に何もないので、インプットを行う必要があった。

業務を遂行するためには「日本で動いている既存のHeader Biddingの構成」と「本件で利用するGCPのサービス」についての知見を貯める必要がある。先に前者について調べることにした。前者を知らないと何をどう作れば良いのかわからないというのと、後者はAさんがDesign Docを書けるぐらいGCPを熟知していたので後回しでも良いと判断したため。

最終的には他者にも共有できるように、メモに近いWikiを書いた。（社内資料なので記載は割愛）

以下にそれまでの過程を示す。

##### 既存構成の理解

- 広告配信の仕組みは事業の根幹であり、息の長い分複雑になっている
- やらなかったこと
  - 今までは開発しながら全体の構成を捉えるようにしていたが、アプリケーションレイヤーまで知る必要はないと判断したので、そのアプローチはやめた
- やったこと
  - Terraformで構成管理されているコードを起点に本件と関わりそうな箇所を聞いたり調べた
    - わからない単語に出会う→読む→聞く→読むを繰り返しながら既存の構成の概略を理解していく
    - 以降は芋づる式で気になったことを聞いている
      - e.g. 
        - (SlackのURLが記載されていたので割愛)
      - その中でも例えばオンプレ時代からの名残のある`Jenkins`は撤去していきたい意向があることが分かった時点で調査をやめたりしている
    - 監視・モニタリング系まで気になり出した時点で「そろそろ作れば？」とアドバイスいただく
      - 一旦既存構成の調査はここまでにした

##### GCPに関する理解

- 前述の「既存構成の理解」に手をつけている間にAさんが途中までGCPリソースを作成していた
- Terraformリソースを読みつつ自身が構成図を書くことで理解を深めた
- 以降は手を動かしつつインプットを進めていった

### タスクの整理

- この時点（2023/07/01ぐらい）である程度、本件に関して業務の遂行および議論ができる状態になった
- ほとんど単独で業務を遂行していたAさんと連携を本格的に取るように
  - 毎日15分ほど話す時間を設けた
- 必要な業務の整理を行う
  - 速度を出すために同時並行で進めそうなものを手分けして進めつつ、要所で一緒に問題解決をするような進め方をとった
- スケジュールの解像度を高める
  - 8月中に動く状態にするにはどのようなマイルストーンをおけば良いかの共通認識をもつ
  - 「動くものを作る」というのを8月中、「リリースできる品質に持っていく」ことを8月中にやろうという話をした

### VMインスタンスをホストするまで

先述のスクリーンショットでタスクの一覧を出したが、「テスト用リクエストを送信してみる」あたりまでの話がこのセクションとなる。

GCPに関するリソース作成周りは主にAさんが担当していた。その間に筆者が行っていたのが「マシンイメージの作成」なので、重点的に書いていく。

#### マシンイメージとは

- https://cloud.google.com/compute/docs/images?hl=ja
- AWSのAMIに相当するもの
- スケールアウトの速度を上げる＆VMインスタンス起動の再現性の担保のために利用される
  - 各種パッケージのインストールをしておく
  - 各種Credentialな情報を定義しておく

#### どのような流れで作られるのか

できあがったフローの簡易的な図を書いた。

（画像が記載できないので割愛）

#### Puppetの設定を追加

- PuppetとPacker、両方を一気に検証するとエラーの解消が難しくなりそうなので前者だけを記述・検証できるようにした
  - 検証用のVMインスタンスを手動で作成し、その中からPuppetの設定を読み込むように
- 途中でS3にある情報が必要だということがわかったのでIAM Userを作成した

#### Packerの設定を追加

- 土台はAさんが書いてくれていたのでそこを加筆修正する形で書いた
- USで動くので従来とタイムゾーンが異なり、記述されていたテストが落ちたので（**配信サーバーのコードを初めて**）修正した

#### 動作確認

- このタイミングでElastigroupの設定が完了したので「作ったものの構成」で記載した画像とほぼ同等の状態になった
- テストリクエスト用のコマンドがあるのでLoad BalancerのIPに対してリクエストを送った（実行時に`HOST`の部分を上書き）
  - 204が返ってきたので、Load Balancerまでの疎通およびアプリケーションが意図通りに起動していることが確認できた

### リリースまでのあれこれ

#### 「リリースできる品質」≒「顧客に提供できる状態」について考える

VMインスタンスを立ち上げられた段階で改めてタスクの整理を行なった。

必要な要素として下記のあたりが挙がった。

1. ログ収集ができていること
2. 監視・アラートの仕組みができていること
3. 動作確認ができていること

これらの詳細について書いていく。

#### ログ収集周り

そもそも顧客に渡す段階で必要なのか？ということも考えたがトラブルシューティングや検知の観点で必要だと判断した。

- 「手作業で確認してメディア経由で広告がでた」=「問題なく動作している」とは言い難い
  - 10回に1回起こるような不具合に気づきづらい
  - 突然起こる不具合に気づきづらい
- 人間の目では気づきづらいところを仕組みでキャッチしておく必要がある

今回のシステムにおけるログは複数種ある。それぞれをどのように対応したのかを書いていく。

##### オークションの参加者・勝者がどこなのかが記録されたログ


- （国内での仕組みと同等にfluentbitを用いてAWS S3に対してログを送るようにした）
- （詳細は割愛）

##### SSP - DSP間でリクエスト・レスポンスのログ

- （国内での仕組みと同等にfluentbitを用いてGCP Big Queryに対してログを送るようにした）
- （詳細は割愛）

##### 標準出力系のログ

- （Google Cloud Loggingを用いて収集するようにした）
- （Grafanaで可視化するように）
- （詳細は割愛）

#### 監視・アラートの仕組み

- ログと同様、「既存の構成と同等の水準にする」方針で進めた
  - 何がどの粒度であると良いのか、という塩梅を判断しかねる（するにしても時間がかかる）
  - 幾多の障害を経て現在の状態になってるので真似が方が良い
  - 設定は既にある仕組みと相似させた方が他者が理解しやすい
- やったこと
  - （国内での仕組みと同等のメトリクスを取り、アラートを設定した）
  - （詳細は割愛）

#### 動作確認を小さく試す

- いきなりUSからのトラフィックを受け付けるのではなく、影響どの小さい国を指定して一時的にトラフィックを流すことで検証することを考えた
- 日本の顧客のみと取引を行なっている当時の段階で「ごく少量のImpressionがある国」からのリクエストをGCPに流す
- 実現可能なのかをBiz側に確認する
    - 多すぎず少なすぎない〇〇imp/dayあり、アメリカに近い地域であるカナダからのトラフィックを受け付けることにした

##### カナダからのリクエストを受け付けた結果

- GCPを経由してImpサーバーに到達していることは確認できた
  - (Slackのリンク)
  - > ひとまずGCPにあるサーバーから出た広告でimpサーバーに到達するところまで確認できた。
    > けど国コードが全てUSなので、カナダに行こうとしてアメリカに進出してしまっている。
- IP判定がRoute53側と配信サーバー側で差分があると考えた
  - 配信サーバーはGeoIPで判定しており、リポジトリのコード変更の度に更新を検知する
  - Route53側は別の仕組みで判定している
    - https://docs.aws.amazon.com/ja_jp/Route53/latest/DeveloperGuide/routing-policy-edns0.html
- `US`だけのトラフィックを取得するように設定すると漏れが出てきそうなので、`北米`全体のリクエストを受け付けることでUS進出しようという話に

##### 北米からのリクエストを受け付けた結果

- 進出前はUSで〇〇imp/dayだったのが、進出後は19時間で〇〇impだった
  - タイムアウトなどでオークションできなかったことによる機会損失が減ったためだと考えられる
  - そのうちGCP（USにあるサーバー）でリクエストを処理したものが〇〇、AWS（日本にあるサーバー）で処理したものが〇〇で、割合だと12.4%が「Route53ではNot US判定したけど配信サーバーではUS判定した」ことになる
- IPによる地理判定の処理が複数種あると乖離は少なからず生まれるので、完璧を求めない
  - 〇〇imp/dayだったものが倍以上になっている時点で十分リクエストは拾えていると判断
  - 大事なのは「儲かるか？（弊社がHeader Biddingで海外の媒体でも入札競争に勝ち、高い単価で多くの広告を表示できるか？）」なので、早いところその不確実性を解消しにいくべき
    - 一応Bさんに相談した

### 事業進捗の可視化

日次・月次でどれくらい儲かっているのか？昨日の配信に問題はなかったか？といったような情報が必要だなと感じたので、ヒアリングをもとに可視化することを試みた。

特に赤字の検知は重要で、以前Open Biddingリリース後しばらく売上だけを取っていたのだが、いざインフラコストの数値も追った際に初めて赤字であることを認知した事例がある。

#### ヒアリング

- 実際に時間をとってヒアリングをしたり、口頭で聞いたりしていた
- （実際の議事録の内容は割愛）

#### 月次で見れる情報

- 先述のヒアリングの通り、用途は下記になる
  - 月次の締め作業に利用する
  - 月単位で推移を追う（注力するべきか否か・撤退するのかなどの判断に利用するものと推察）
- 国内のHeader Biddingにおける情報はスプレッドシートで管理している（実際のURLは割愛）
  - [Amazon Quick Sight](https://aws.amazon.com/jp/quicksight/)経由で取得した情報を月次でスプレッドシートに転載していることがヒアリングを通して分かった
  - よって海外Verも同様のフローを取った

#### 日次で見れる情報

- 先述のヒアリングの通り、用途は下記になる
  - 事故防止・赤字の検知
- 国内のHeader BiddingだとBizの方がかいた秘伝のクエリで賄っている（実際のRedashのURLは割愛）
  - サーバーコストが手入力であって、正確でない
  - 特にUS進出初期においては正確な数値を知りたいという話だったので、これは踏襲しない方向にした
- 欲しい情報まとめ
  - レポート情報
    - これはQuickSightまたはRedashから取得できる
  - インフラコスト
    - 弊社だと手動でのみ取得している
  - 両者を横串で見るとなると、最終的には使い慣れてるスプレッドシートでみれるのがBiz側としてはありがたい
- RedashだとAPIとスプレッドシートが連携することでエクスポートが容易にできる
  - 一方でデータチームとしてはRedashやめたい雰囲気がある
  - 改めて意向を聞いてみるとこのような話があった(実情の話は割愛)
    - よっていずれ別のツールを使う前提でRedashを用いる方向に
- 最終的にはRedashとスプレッドシートを使い慣れているBiz側にフォーマットや運用方法は考えてもらった
  - (実際の運用方法の説明はデモが必要なので割愛)

## 結果まとめ

- USに配信サーバーをホストすることができた
- 日次・月次の運用も回せる状態になった
- 徐々に営業サイドが顧客を捕まえてきて配信が本格的に始まり、売り上げがでてくる予定

## 今後の展望

- 落ち穂拾いなお仕事をやっていく
  - 本件のリリースのクリティカルパスにないものは随時メモっていた
